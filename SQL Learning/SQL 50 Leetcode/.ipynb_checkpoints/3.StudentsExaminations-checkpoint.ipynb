{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f48e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/29 12:10:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/02/29 12:10:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|student_id|student_name|\n",
      "+----------+------------+\n",
      "|         1|       Alice|\n",
      "|         2|         Bob|\n",
      "|        13|        John|\n",
      "|         6|        Alex|\n",
      "+----------+------------+\n",
      "\n",
      "+------------+\n",
      "|subject_name|\n",
      "+------------+\n",
      "|        Math|\n",
      "|     Physics|\n",
      "| Programming|\n",
      "+------------+\n",
      "\n",
      "+----------+------------+\n",
      "|student_id|subject_name|\n",
      "+----------+------------+\n",
      "|         1|        Math|\n",
      "|         1|     Physics|\n",
      "|         1| Programming|\n",
      "|         2| Programming|\n",
      "|         1|     Physics|\n",
      "|         1|        Math|\n",
      "|        13|        Math|\n",
      "|        13| Programming|\n",
      "|        13|     Physics|\n",
      "|         2|        Math|\n",
      "|         1|        Math|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CreateDataFrames\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data for Students table\n",
    "students_data = [\n",
    "    (1, 'Alice'),\n",
    "    (2, 'Bob'),\n",
    "    (13, 'John'),\n",
    "    (6, 'Alex')\n",
    "]\n",
    "\n",
    "# Sample data for Subjects table\n",
    "subjects_data = [\n",
    "    ('Math',),\n",
    "    ('Physics',),\n",
    "    ('Programming',)\n",
    "]\n",
    "\n",
    "# Sample data for Examinations table\n",
    "examinations_data = [\n",
    "    (1, 'Math'),\n",
    "    (1, 'Physics'),\n",
    "    (1, 'Programming'),\n",
    "    (2, 'Programming'),\n",
    "    (1, 'Physics'),\n",
    "    (1, 'Math'),\n",
    "    (13, 'Math'),\n",
    "    (13, 'Programming'),\n",
    "    (13, 'Physics'),\n",
    "    (2, 'Math'),\n",
    "    (1, 'Math')\n",
    "]\n",
    "\n",
    "# Create DataFrames\n",
    "students_df = spark.createDataFrame(students_data, [\"student_id\", \"student_name\"])\n",
    "subjects_df = spark.createDataFrame(subjects_data, [\"subject_name\"])\n",
    "examinations_df = spark.createDataFrame(examinations_data, [\"student_id\", \"subject_name\"])\n",
    "\n",
    "# Show DataFrames\n",
    "students_df.show()\n",
    "subjects_df.show()\n",
    "examinations_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6885ff-f073-46c5-b7b0-c2d45e870a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d975eb7e-6d28-470e-924d-6b565e5d3cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------+\n",
      "|student_id|subject_name|attended_exams|\n",
      "+----------+------------+--------------+\n",
      "|         1|        Math|             3|\n",
      "|         1|     Physics|             2|\n",
      "|         1| Programming|             1|\n",
      "|         2|        Math|             1|\n",
      "|         2| Programming|             1|\n",
      "|        13|        Math|             1|\n",
      "|        13|     Physics|             1|\n",
      "|        13| Programming|             1|\n",
      "+----------+------------+--------------+\n",
      "\n",
      "+----------+------------+--------------+\n",
      "|student_id|subject_name|attended_exams|\n",
      "+----------+------------+--------------+\n",
      "|         1|        Math|             3|\n",
      "|         1|     Physics|             2|\n",
      "|         1| Programming|             1|\n",
      "|         2|        Math|             1|\n",
      "|         2| Programming|             1|\n",
      "|        13|        Math|             1|\n",
      "|        13|     Physics|             1|\n",
      "|        13| Programming|             1|\n",
      "+----------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Join students_df and examinations_df\n",
    "result_df = students_df.join(examinations_df, 'student_id', 'left')\n",
    "\n",
    "# Group by student_id and subject_name, and count occurrences\n",
    "result_df = result_df.groupBy('student_id', 'subject_name').count()\n",
    "\n",
    "# Rename the 'count' column to 'attended_exams'\n",
    "result_df = result_df.withColumnRenamed('count', 'attended_exams')\n",
    "\n",
    "# Order by student_id and subject_name\n",
    "result_df = result_df.orderBy('student_id', 'subject_name').filter(F.col('subject_name').isNotNull())\n",
    "\n",
    "resulf_df = result_df.filter\n",
    "\n",
    "# Show the result\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6bef35-03be-4c43-9e7d-bf259ec22621",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Generate all possible combinations of students and subjects\n",
    "WITH all_combinations AS (\n",
    "    SELECT \n",
    "        s.student_id,\n",
    "        s.student_name,\n",
    "        sj.subject_name\n",
    "    FROM \n",
    "        Students s\n",
    "    CROSS JOIN \n",
    "        Subjects sj\n",
    ")\n",
    " # Left join with Examinations to count attended exams\n",
    "SELECT \n",
    "    ac.student_id,\n",
    "    ac.student_name,\n",
    "    ac.subject_name,\n",
    "    COUNT(e.subject_name) AS attended_exams\n",
    "FROM \n",
    "    all_combinations ac\n",
    "LEFT JOIN \n",
    "    Examinations e ON ac.student_id = e.student_id AND ac.subject_name = e.subject_name\n",
    "GROUP BY \n",
    "    ac.student_id, ac.student_name, ac.subject_name\n",
    "ORDER BY \n",
    "    ac.student_id, ac.subject_name;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa4b60-99a4-4395-9cc3-128cf95e8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT s.student_id, s.student_name, sub.subject_name, COUNT(e.subject_name) AS attended_exams\n",
    "FROM Students s\n",
    "CROSS JOIN Subjects sub\n",
    "LEFT JOIN Examinations e ON s.student_id = e.student_id AND sub.subject_name = e.subject_name\n",
    "GROUP BY s.student_id, s.student_name, sub.subject_name\n",
    "ORDER BY s.student_id, sub.subject_name;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
