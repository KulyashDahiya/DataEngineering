{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab67b774-389e-42c4-8c7d-46a0b2451458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    machine_id  process_id activity_type  timestamp\n",
      "0            0           0         start      0.712\n",
      "1            0           0           end      1.520\n",
      "2            0           1         start      3.140\n",
      "3            0           1           end      4.120\n",
      "4            1           0         start      0.550\n",
      "5            1           0           end      1.550\n",
      "6            1           1         start      0.430\n",
      "7            1           1           end      1.420\n",
      "8            2           0         start      4.100\n",
      "9            2           0           end      4.512\n",
      "10           2           1         start      2.500\n",
      "11           2           1           end      5.000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'machine_id': [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],\n",
    "    'process_id': [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n",
    "    'activity_type': ['start', 'end', 'start', 'end', 'start', 'end', 'start', 'end', 'start', 'end', 'start', 'end'],\n",
    "    'timestamp': [0.712, 1.520, 3.140, 4.120, 0.550, 1.550, 0.430, 1.420, 4.100, 4.512, 2.500, 5.000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b893e246-bada-4369-b9b7-d03470eee4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    machine_id  process_id activity_type  timestamp  processing_time\n",
      "0            0           0         start      0.712              NaN\n",
      "1            0           0           end      1.520            0.808\n",
      "2            0           1         start      3.140              NaN\n",
      "3            0           1           end      4.120            0.980\n",
      "4            1           0         start      0.550              NaN\n",
      "5            1           0           end      1.550            1.000\n",
      "6            1           1         start      0.430              NaN\n",
      "7            1           1           end      1.420            0.990\n",
      "8            2           0         start      4.100              NaN\n",
      "9            2           0           end      4.512            0.412\n",
      "10           2           1         start      2.500              NaN\n",
      "11           2           1           end      5.000            2.500\n",
      "\n",
      "     machine_id  process_id activity_type  timestamp  processing_time\n",
      "1            0           0           end      1.520            0.808\n",
      "3            0           1           end      4.120            0.980\n",
      "5            1           0           end      1.550            1.000\n",
      "7            1           1           end      1.420            0.990\n",
      "9            2           0           end      4.512            0.412\n",
      "11           2           1           end      5.000            2.500\n",
      "\n",
      "    machine_id  processing_time\n",
      "0           0            0.894\n",
      "1           1            0.995\n",
      "2           2            1.456\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate processing time for each process\n",
    "df['processing_time'] = df.groupby(['machine_id', 'process_id'])['timestamp'].diff()\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Drop rows where activity_type is 'start' (to keep only end timestamps)\n",
    "df = df[df['activity_type'] == 'end']\n",
    "\n",
    "print(\"\\n\", df)\n",
    "\n",
    "# Group by machine_id and calculate average processing time\n",
    "result = df.groupby('machine_id')['processing_time'].mean().reset_index()\n",
    "\n",
    "# Round processing time to 3 decimal places\n",
    "result['processing_time'] = result['processing_time'].round(3)\n",
    "\n",
    "print(\"\\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59708c0d-cfce-47d7-9bde-e6278e8be2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmachine_id\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess_id\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity_type\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.712\u001b[39m, \u001b[38;5;241m1.520\u001b[39m, \u001b[38;5;241m3.140\u001b[39m, \u001b[38;5;241m4.120\u001b[39m, \u001b[38;5;241m0.550\u001b[39m, \u001b[38;5;241m1.550\u001b[39m, \u001b[38;5;241m0.430\u001b[39m, \u001b[38;5;241m1.420\u001b[39m, \u001b[38;5;241m4.100\u001b[39m, \u001b[38;5;241m4.512\u001b[39m, \u001b[38;5;241m2.500\u001b[39m, \u001b[38;5;241m5.000\u001b[39m]\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(pd\u001b[38;5;241m.\u001b[39mDataFrame(data))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate processing time for each process\u001b[39;00m\n\u001b[1;32m     22\u001b[0m window_spec \u001b[38;5;241m=\u001b[39m Window\u001b[38;5;241m.\u001b[39mpartitionBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmachine_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CalculateAverageProcessingTime\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'machine_id': [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],\n",
    "    'process_id': [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n",
    "    'activity_type': ['start', 'end', 'start', 'end', 'start', 'end', 'start', 'end', 'start', 'end', 'start', 'end'],\n",
    "    'timestamp': [0.712, 1.520, 3.140, 4.120, 0.550, 1.550, 0.430, 1.420, 4.100, 4.512, 2.500, 5.000]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(pd.DataFrame(data))\n",
    "\n",
    "# Calculate processing time for each process\n",
    "window_spec = Window.partitionBy('machine_id', 'process_id').orderBy('timestamp')\n",
    "df = df.withColumn('processing_time', \n",
    "                   (F.col('timestamp') - \n",
    "                    F.lag('timestamp', default=0).over(window_spec)))\n",
    "\n",
    "# Filter out 'start' activities\n",
    "df = df.filter(df.activity_type == 'end')\n",
    "\n",
    "result = df.groupBy('machine_id').agg(F.round(F.avg('processing_time'), 3).alias('processing_time'))\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb12296-4902-4841-8ca3-fc01a77e59e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CalculateAverageProcessingTime\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'machine_id': [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],\n",
    "    'process_id': [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n",
    "    'activity_type': ['start', 'end', 'start', 'end', 'start', 'end', 'start', 'end', 'start', 'end', 'start', 'end'],\n",
    "    'timestamp': [0.712, 1.520, 3.140, 4.120, 0.550, 1.550, 0.430, 1.420, 4.100, 4.512, 2.500, 5.000]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(pd.DataFrame(data))\n",
    "\n",
    "# Create a temporary view\n",
    "df.createOrReplaceTempView(\"activity_table\")\n",
    "\n",
    "r1 = spark.sql(\"\"\"select * from activity_table\"\"\")\n",
    "r1.show()\n",
    "\n",
    "# SQL query to calculate processing time and average processing time\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        machine_id,\n",
    "        round(AVG(processing_time), 3) AS processing_time\n",
    "    FROM (\n",
    "        SELECT \n",
    "            machine_id,\n",
    "            process_id,\n",
    "            MAX(timestamp) - MIN(timestamp) AS processing_time\n",
    "        FROM \n",
    "            activity_table\n",
    "        GROUP BY\n",
    "            machine_id, process_id\n",
    "    ) t\n",
    "    GROUP BY \n",
    "        machine_id\n",
    "\"\"\")\n",
    "\n",
    "# Show the result\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc1566c-2c7f-453c-b69c-82f54768ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your MySQL query statement below\n",
    "WITH ProcessTimes AS\n",
    "    SELECT \n",
    "        machine_id,\n",
    "        process_id,\n",
    "        MAX(timestamp) - MIN(timestamp) AS processing_time\n",
    "    FROM \n",
    "        Activity\n",
    "    GROUP BY\n",
    "        machine_id, process_id\n",
    ")\n",
    "SELECT \n",
    "    machine_id,\n",
    "    round(AVG(processing_time), 3) AS processing_time\n",
    "FROM \n",
    "    ProcessTimes\n",
    "GROUP BY \n",
    "    machine_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b2a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "select a.machine_id, a.process_id, a.activity_type, b.activity_type, a.timestamp, b.timestamp\n",
    "from Activity a\n",
    "join Activity b\n",
    "on a.machine_id = b.machine_id and a.process_id = b.process_id and a.activity_type='start' and b.activity_type='end'\n",
    "\n",
    "\n",
    "select a.machine_id, round(avg((b.timestamp - a.timestamp)), 3) as processing_time\n",
    "from Activity a\n",
    "join Activity b\n",
    "on a.machine_id = b.machine_id and a.process_id = b.process_id and a.activity_type='start' and b.activity_type='end'\n",
    "group by a.machine_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ab506",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT a1.machine_id,\n",
    "    ROUND(SUM(a2.timestamp-a1.timestamp)/COUNT(distinct a1.process_id),3)AS processing_time\n",
    "FROM Activity a1\n",
    "JOIN Activity a2 ON a1.machine_id=a2.machine_id AND a1.process_id=a2.process_id AND a1.activity_type!=a2.activity_type AND a1.timestamp < a2.timestamp\n",
    "GROUP BY machine_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
