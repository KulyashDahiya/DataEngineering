{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Initialize findspark and SparkSession\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[12]\")\\\n",
    "        .appName(\"testing\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Customer Data\n",
    "customer_data = [\n",
    "    (1, 'manish', 'patna', \"30-05-2022\"),\n",
    "    (2, 'vikash', 'kolkata', \"12-03-2023\"),\n",
    "    (3, 'nikita', 'delhi', \"25-06-2023\"),\n",
    "    (4, 'rahul', 'ranchi', \"24-03-2023\"),\n",
    "    (5, 'mahesh', 'jaipur', \"22-03-2023\"),\n",
    "    (6, 'prantosh', 'kolkata', \"18-10-2022\"),\n",
    "    (7, 'raman', 'patna', \"30-12-2022\"),\n",
    "    (8, 'prakash', 'ranchi', \"24-02-2023\"),\n",
    "    (9, 'ragini', 'kolkata', \"03-03-2023\"),\n",
    "    (10, 'raushan', 'jaipur', \"05-02-2023\")\n",
    "]\n",
    "\n",
    "# Define Customer Schema\n",
    "customer_schema = StructType([\n",
    "    StructField('customer_id', IntegerType(), True),\n",
    "    StructField('customer_name', StringType(), True),\n",
    "    StructField('customer_address', StringType(), True),\n",
    "    StructField('DateOfJoining', StringType(), True),\n",
    "])\n",
    "\n",
    "# Create Customer DataFrame\n",
    "customer_df = spark.createDataFrame(customer_data, customer_schema)\n",
    "\n",
    "# Convert DateOfJoining to DateType\n",
    "# customer_df = customer_df.withColumn(\"DateOfJoining\", to_date(col(\"DateOfJoining\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "# Show Customer DataFrame\n",
    "print(\"Customer DataFrame:\")\n",
    "customer_df.show()\n",
    "\n",
    "# Sales Data\n",
    "sales_data = [\n",
    "    (1, 22, 10, \"01-06-2022\"),\n",
    "    (1, 27, 5, \"03-02-2023\"),\n",
    "    (2, 5, 3, \"01-06-2023\"),\n",
    "    (5, 22, 1, \"22-03-2023\"),\n",
    "    (7, 22, 4, \"03-02-2023\"),\n",
    "    (9, 5, 6, \"03-03-2023\"),\n",
    "    (2, 1, 12, \"15-06-2023\"),\n",
    "    (1, 56, 2, \"25-06-2023\"),\n",
    "    (5, 12, 5, \"15-04-2023\"),\n",
    "    (11, 12, 76, \"12-03-2023\")\n",
    "]\n",
    "\n",
    "# Define Sales Schema\n",
    "sales_schema = StructType([\n",
    "    StructField('customer_id', IntegerType(), True),\n",
    "    StructField('product_id', IntegerType(), True),\n",
    "    StructField('quantity', IntegerType(), True),\n",
    "    StructField('sale_date', StringType(), True),\n",
    "])\n",
    "\n",
    "# Create Sales DataFrame\n",
    "sales_df = spark.createDataFrame(sales_data, sales_schema)\n",
    "\n",
    "# Convert sale_date to DateType\n",
    "# sales_df = sales_df.withColumn(\"sale_date\", to_date(col(\"sale_date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "# Show Sales DataFrame\n",
    "print(\"Sales DataFrame:\")\n",
    "sales_df.show()\n",
    "\n",
    "\n",
    "# sortmergedf = customer_df.join(sales_df, customer_df.customer_id == sales_df.customer_id, \"inner\")\n",
    "#\n",
    "# sortmergedf.show()\n",
    "#\n",
    "# # sortmergedf.printSchema()\n",
    "#\n",
    "# sortmergedf.explain()\n",
    "\n",
    "\n",
    "broadcast_df = customer_df.join(broadcast(sales_df), customer_df.customer_id == sales_df.customer_id, \"inner\")\n",
    "\n",
    "broadcast_df.show()\n",
    "\n",
    "broadcast_df.explain()\n",
    "\n",
    "\n",
    "input(\"Press enter to terminate\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "fdf5ee93f99441bc"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
